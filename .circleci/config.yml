version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
   aws-cli: circleci/aws-cli@2.0.3
# Define the jobs we want to run for this project
jobs:
  myjob1:  # Choose any name, such as `build`
      # The primary container, where your job's commands will run
      docker:
        - image: circleci/node:13.8.0
      steps:
        - checkout # check out the code in the project directory
        - run: echo "hello world" # run the `echo` command




  # Exercise - Rollback
  
          


  # Exercise: Sharing Files (Job names may have changed)
  
 
  # Exercise: Infrastructure Creation
  # Exercise - Rollback
  create_infrastructure: 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
              --region us-east-1
      # Fail the job intentionally to simulate an error.
      # Uncomment the line below if you want to fail the current step
      # - run: return 1
      


  # Exercise: Config and Deployment
configure_infrastructure: 
  docker:
    - image: python:3.7-alpine3.11
  steps:
    - checkout
    - add_ssh_keys:
            # You can get this ID in the section where you registered the SSH Key
            fingerprints: ["34:be:dc:83:2a:00:6e:45:c0:fe:3f:ec:83:36:63:2b"] 
    - run:
        name: Install Ansible
        command: |
          apk add --update ansible
i    - run:
        name: Run Playbook and Configure server
        command: |
         ansible-playbook -i inventory.txt main4.yml
  
  # Exercise: Smoke Testing
 
  # Exercise: Promote to Production - Job 1 
  # Prerequisite: 
  # 1. An S3 bucket (say `mybucket644752792305`) with a sample index.html created manually in your AWS console. 
  # 2. Enable the Static website hosting in that bucket.
  # 3. Run the command below to create a CloudFront Distribution that will connect to the existing bucket. 
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the cloudfront.yml template file.
  # We are assuming that the `PipelineID` parameter represents the bucket ID. 

  # aws cloudformation deploy \
  # --template-file cloudfront.yml \
  # --stack-name production-distro \
  # --parameter-overrides PipelineID="${S3_BUCKET_NAME}" \ # Name of the S3 bucket you created manually.
  
  # Job 1
  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  
  # Exercise: Promote to Production - Job 2
  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  
  
  # Exercise: Promote to Production - Job 3
  # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  

  # Exercise: Promote to Production - Job 4
  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  
          #  aws cloudformation delete-stack --stack-name production-distro 
          #  aws cloudformation delete-stack --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7}
          #  aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}



workflows:
  # Name the workflow "welcome"
  my_workflow:
    # Run the welcome/run job in its own container
    jobs:
    - myjob1
    - create_infrastructure
